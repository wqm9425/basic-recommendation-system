{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baobao/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    }
   ],
   "source": [
    "cols = ['UserID', 'MovieID', 'Rating', 'Timestamp']\n",
    "# load data\n",
    "file = 'data/ratings.dat'\n",
    "df = pd.read_csv(file, sep='::', names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data\n",
    "train_set, test_set = train_test_split(df, test_size = 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build zero data set \n",
    "n_users = train_set['UserID'].max()\n",
    "n_items = train_set['MovieID'].max()\n",
    "ratings = np.zeros((n_users, n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill rating in training set [user, movie]\n",
    "for row in train_set.itertuples():\n",
    "    ratings[row[1]-1, row[2]-1] = row[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define loss function\n",
    "def rmse(pred, actual):\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return np.sqrt(mean_squared_error(pred, actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3952)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ——————————baseline——————————\n",
    "def cal_mean(training_matrix):\n",
    "    global all_mean, user_mean, item_mean\n",
    "    all_mean = np.mean(training_matrix[training_matrix!=0])\n",
    "    user_mean = sum(training_matrix.T) / sum((training_matrix!=0).T)\n",
    "    item_mean = sum(training_matrix) / sum((training_matrix!=0)) # sum up each col.\n",
    "    \n",
    "    if np.isnan(user_mean).any():\n",
    "        user_mean_nan = True\n",
    "    else:\n",
    "        user_mean_nan = False\n",
    "    if np.isnan(item_mean).any():\n",
    "        item_mean_nan = True\n",
    "    else:\n",
    "        item_mean_nan = False\n",
    "    print('Existing User_NaN?', user_mean_nan)\n",
    "    print('Existing Item_NaN?', item_mean_nan)\n",
    "\n",
    "    # fill with all_mean while user/item mean isnan\n",
    "    user_mean = np.where(np.isnan(user_mean), all_mean, user_mean)\n",
    "    item_mean = np.where(np.isnan(item_mean), all_mean, item_mean)\n",
    "    \n",
    "    if np.isnan(user_mean).any():\n",
    "        user_mean_nan = True\n",
    "    else:\n",
    "        user_mean_nan = False\n",
    "    if np.isnan(item_mean).any():\n",
    "        item_mean_nan = True\n",
    "    else:\n",
    "        item_mean_nan = False\n",
    "    print('Existing User_NaN?', user_mean_nan)\n",
    "    print('Existing Item_NaN?', item_mean_nan)\n",
    "    print('all_mean %.4f' % all_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing User_NaN? False\n",
      "Existing Item_NaN? True\n",
      "Existing User_NaN? False\n",
      "Existing Item_NaN? False\n",
      "all_mean 3.5815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baobao/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "cal_mean(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate similarity by Cosine \n",
    "def cal_similarity(ratings, kind, epsilon=1e-9):\n",
    "    # kind: calculate similarity based on user or item A.T@B/|A||B|\n",
    "    # epsilon: prevent 1/0 \n",
    "    if kind == 'user':\n",
    "        similarity = ratings.dot(ratings.T) + epsilon\n",
    "    elif kind == 'item':\n",
    "        similarity = ratings.T.dot(ratings) + epsilon\n",
    "    square_vec = 1/np.diag(similarity)\n",
    "    abs_vec = np.sqrt(square_vec)\n",
    "    cosine = similarity * abs_vec\n",
    "    cosine = cosine.T * abs_vec\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.    0.308 0.222 0.141 0.208 0.285 0.235 0.108 0.096 0.314]\n",
      " [0.308 1.    0.187 0.115 0.209 0.205 0.211 0.116 0.149 0.293]\n",
      " [0.222 0.187 1.    0.167 0.22  0.137 0.211 0.058 0.103 0.194]\n",
      " [0.141 0.115 0.167 1.    0.211 0.094 0.156 0.056 0.04  0.105]\n",
      " [0.208 0.209 0.22  0.211 1.    0.126 0.222 0.07  0.098 0.208]\n",
      " [0.285 0.205 0.137 0.094 0.126 1.    0.151 0.053 0.129 0.348]\n",
      " [0.235 0.211 0.211 0.156 0.222 0.151 1.    0.047 0.061 0.201]\n",
      " [0.108 0.116 0.058 0.056 0.07  0.053 0.047 1.    0.041 0.078]\n",
      " [0.096 0.149 0.103 0.04  0.098 0.129 0.061 0.041 1.    0.161]\n",
      " [0.314 0.293 0.194 0.105 0.208 0.348 0.201 0.078 0.161 1.   ]]\n"
     ]
    }
   ],
   "source": [
    "user_similarity = cal_similarity(ratings, kind='user')\n",
    "item_similarity = cal_similarity(ratings, kind='item')\n",
    "# item similarity\n",
    "print(np.round_(item_similarity[:10,:10], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation on test\n",
    "def test_model(model, loss_function):\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    print('_____%s_____' % model)\n",
    "    for row in test_set.itertuples():\n",
    "        user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "        predictions.append(model(user, item))\n",
    "        targets.append(actual)\n",
    "\n",
    "    print('rmse is %.4f' % loss_function(np.array(predictions), np.array(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____<function predict_itemCF at 0x1127f3b70>_____\n",
      "rmse is 1.0025\n"
     ]
    }
   ],
   "source": [
    "# item based CF\n",
    "def predict_itemCF(user, item):\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    prediction = ratings[user, nzero].dot(item_similarity[item, nzero])\\\n",
    "                / sum(item_similarity[item, nzero])\n",
    "    return prediction\n",
    "test_model(predict_itemCF, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# item based CF with baseline\n",
    "def predict_itemCF_baseline(user, item):\n",
    "    nzero = ratings[user].nonzero()[0] # index of nonzero item\n",
    "    # bias_user + bias_item + all_mean (baseline of a list of item)\n",
    "    baseline = item_mean + user_mean[user] - all_mean \n",
    "    prediction = (ratings[user, nzero] - baseline[nzero]).dot(item_similarity[item, nzero])\\\n",
    "                / sum(item_similarity[item, nzero]) + baseline[item] \n",
    "#     if prediction > 5:\n",
    "#         prediction = 5\n",
    "#     if prediction < 1:\n",
    "#         prediciton = 1    \n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____<function predict_itemCF_baseline at 0x1134359d8>_____\n",
      "rmse is 0.8955\n"
     ]
    }
   ],
   "source": [
    "test_model(predict_itemCF_baseline, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# user based CF with baseline\n",
    "def predict_userCF_baseline(user, item):\n",
    "    nzero = ratings[:,item].nonzero()[0]\n",
    "    baseline = user_mean + item_mean[item] - all_mean\n",
    "    prediction = (ratings[nzero, item] - baseline[nzero]).dot(user_similarity[user, nzero])\\\n",
    "                / sum(user_similarity[user, nzero]) + baseline[user]\n",
    "    # no ratings on this item\n",
    "    if np.isnan(prediction):\n",
    "        prediction = baseline[user]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____<function predict_userCF_baseline at 0x1127f37b8>_____\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baobao/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:5: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse is 0.9233\n"
     ]
    }
   ],
   "source": [
    "test_model(predict_userCF_baseline, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding top k method to item based CF\n",
    "def predict_topkCF(user, item, k=10):\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    baseline = item_mean + user_mean[user] - all_mean\n",
    "    choice = nzero[item_similarity[item, nzero].argsort()[::-1][:k]] # top k similarity\n",
    "    prediction = (ratings[user, choice] - baseline[choice]).dot(item_similarity[item, choice])\\\n",
    "                / sum(item_similarity[item, choice]) + baseline[item]\n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____<function predict_topkCF at 0x113435a60>_____\n",
      "rmse is 0.8743\n"
     ]
    }
   ],
   "source": [
    "test_model(predict_topkCF, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize similarity using Pearson correlation coefficient\n",
    "def cal_similarity_norm(ratings, kind, epsilon=1e-9):\n",
    "    if kind == 'user':\n",
    "        # normalization\n",
    "        rating_user_diff = ratings.copy()\n",
    "        for i in range(ratings.shape[0]):\n",
    "            nzero = ratings[i].nonzero()\n",
    "            rating_user_diff[i][nzero] = ratings[i][nzero] - user_mean[i]\n",
    "        similarity = rating_user_diff.dot(rating_user_diff.T) + epsilon\n",
    "    elif kind == 'item':\n",
    "        rating_item_diff = ratings.copy()\n",
    "        for j in range(ratings.shape[1]):\n",
    "            nzero = ratings[:,j].nonzero()\n",
    "            rating_item_diff[:,j][nzero] = ratings[:,j][nzero] - item_mean[j]\n",
    "        similarity = rating_item_diff.T.dot(rating_item_diff) + epsilon\n",
    "    square_vec = 1/np.diag(similarity)\n",
    "    # square_vec[np.isinf(square_vec)] = 0\n",
    "    abs_vec = np.sqrt(square_vec)\n",
    "    cosine = similarity * abs_vec\n",
    "    cosine = cosine.T * abs_vec\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.    0.308 0.222 0.141 0.208 0.285 0.235 0.108 0.096 0.314]\n",
      " [0.308 1.    0.187 0.115 0.209 0.205 0.211 0.116 0.149 0.293]\n",
      " [0.222 0.187 1.    0.167 0.22  0.137 0.211 0.058 0.103 0.194]\n",
      " [0.141 0.115 0.167 1.    0.211 0.094 0.156 0.056 0.04  0.105]\n",
      " [0.208 0.209 0.22  0.211 1.    0.126 0.222 0.07  0.098 0.208]\n",
      " [0.285 0.205 0.137 0.094 0.126 1.    0.151 0.053 0.129 0.348]\n",
      " [0.235 0.211 0.211 0.156 0.222 0.151 1.    0.047 0.061 0.201]\n",
      " [0.108 0.116 0.058 0.056 0.07  0.053 0.047 1.    0.041 0.078]\n",
      " [0.096 0.149 0.103 0.04  0.098 0.129 0.061 0.041 1.    0.161]\n",
      " [0.314 0.293 0.194 0.105 0.208 0.348 0.201 0.078 0.161 1.   ]]\n"
     ]
    }
   ],
   "source": [
    "user_similarity_norm = cal_similarity_norm(ratings, kind='user')\n",
    "item_similarity_norm = cal_similarity_norm(ratings, kind='item')\n",
    "print(np.round_(item_similarity[:10,:10], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding normalization to item based CF\n",
    "def predict_norm_CF(user, item, k=30):\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    baseline = item_mean + user_mean[user] - all_mean\n",
    "    choice = nzero[item_similarity_norm[item, nzero].argsort()[::-1][:k]]\n",
    "    prediction = (ratings[user, choice] - baseline[choice]).dot(item_similarity_norm[item, choice])\\\n",
    "                / sum(item_similarity_norm[item, choice]) + baseline[item]\n",
    "    if prediction > 5: \n",
    "        prediction = 5\n",
    "    if prediction < 1: \n",
    "        prediction = 1\n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____<function predict_norm_CF at 0x113424510>_____\n",
      "rmse is 0.8543\n"
     ]
    }
   ],
   "source": [
    "test_model(predict_norm_CF, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
